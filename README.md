# Native Instruments - dbt Data Pipeline

Professional dbt project with BigQuery integration for data analytics.

## ğŸš€ Project Overview

This project implements a complete **end-to-end data pipeline** using:
- âœ… **dbt Core** with BigQuery
- âœ… **Professional data architecture** (staging â†’ core â†’ marts)
- âœ… **Comprehensive testing & documentation**
- âœ… **Test data for development**

## ğŸ“Š Architecture

```
ğŸ“ Data Layers
â”œâ”€â”€ ğŸŒ± Seeds (CSV test data)
â”œâ”€â”€ ğŸ”§ Staging (data cleaning)
â”œâ”€â”€ ğŸ—ï¸ Core (dimensions & facts)  
â””â”€â”€ ğŸ“ˆ Marts (business ready)
```

### BigQuery Structure
```
Development:     bqni-466316.DEV_staging.*
                bqni-466316.DEV_core.*
                bqni-466316.DEV_marts.*

Production:      bqni-466316.dbt_staging.*
                bqni-466316.dbt_core.*
                bqni-466316.dbt_marts.*
```

## ğŸ› ï¸ Setup

### Prerequisites
- Python 3.11+
- BigQuery project with credentials
- Virtual environment with dbt-bigquery

### Quick Start

1. **Clone and setup:**
```bash
git clone https://github.com/JCGlez93/native_instruments.git
cd native_instruments
source dbt_env/bin/activate  # Activate virtual environment
```

2. **Load environment:**
```bash
source load_env.sh
```

3. **Run pipeline:**
```bash
dbt seed      # Load test data
dbt run       # Execute models
dbt test      # Validate data
dbt docs generate && dbt docs serve  # View docs
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/     # Data cleaning & standardization
â”‚   â”œâ”€â”€ core/        # Dimensions & fact tables
â”‚   â””â”€â”€ marts/       # Business-ready analytics
â”œâ”€â”€ seeds/           # Test data (CSV files)
â”œâ”€â”€ macros/          # Custom dbt macros  
â””â”€â”€ tests/           # Data quality tests
```

## ğŸ¯ Key Features

- âœ… **End-to-end tested** pipeline
- âœ… **Professional naming** conventions
- âœ… **Comprehensive documentation** 
- âœ… **Multi-environment** setup
- âœ… **Industry best practices**
- âœ… **BigQuery optimized** models

## ğŸ“ Models

### Seeds
- `users_test.csv` - Test user data
- `events_test.csv` - Test event data

### Staging
- `stg_users_test` - Cleaned user data
- `stg_events_test` - Cleaned event data

### Core
- `dim_users_test` - User dimension table
- `fct_events_test` - Event fact table

### Marts
- `user_engagement_summary_test` - User engagement analytics

## ğŸ”§ Configuration

The project uses environment variables for BigQuery connection:
- `BIGQUERY_PROJECT_ID`
- `BIGQUERY_DATASET_DEV`
- `BIGQUERY_DATASET_STAGING`
- etc.

Configure these in your `.env` file or load them using `load_env.sh`.
